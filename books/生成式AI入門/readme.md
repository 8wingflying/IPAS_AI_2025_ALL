# 生成式 AI 入門
- [生成式 AI 入門](https://learning.oreilly.com/library/view/introduction-to-generative/9781633437197/)
- 1 Large language models: The power of AI
- 2 Training large language models
- 3 Data privacy and safety with LLMs
- 4 The evolution of created content
- 5 Misuse and adversarial attacks
- 6 Accelerating productivity: Machine-augmented work
- 7 Making social connections with chatbots
- 8 What’s next for AI and LLMs
- 9 Broadening the horizon: Exploratory topics in AI

```
第 1 章 大型語言模型：展現 AI 實力
1.1 ChatGPT 與大型語言模型的崛起
1.2 自然語言處理的起源與演進
1.2.1 統計模型與機器學習的引入
1.2.2 神經網路與深度學習的崛起
1.3 大型語言模型（LLM）的誕生
1.3.1 注意力機制的誕生與應用
1.3.2 Transformer 架構帶來突破
1.3.3 從 Transformer 到 GPT
1.3.4 NLP 發展的重要時間點
1.4 LLMs 有哪些應用？
1.4.1 語言建模
1.4.2 程式碼生成
1.4.3 內容生成
1.4.4 邏輯推理
1.4.5 其它各種應用
1.5 LLMs 有哪些不足之處？
1.5.1 訓練資料與偏見
1.5.2 控制 LLMs 輸出正確性的困難
1.5.3 LLMs 的永續性
1.6 重要 LLM 的發展歷程
1.6.1 OpenAI 的 ChatGPT
1.6.2 Google 的 Bard / LaMDA / PaLM / Gemini
1.6.3 微軟的 Bing AI / Copilot
1.6.4 Meta 的 LLaMA 與史丹佛的 Alpaca
1.6.5 橫空出世的 DeepSeek
1.7 總結
```
```
第 2 章 訓練大型語言模型（LLMs）
2.1 如何訓練 LLMs
2.1.1 從開放網路搜集資料
2.1.2 認識自迴歸模型與雙向模型
2.1.3 微調 LLMs
2.2 出人意料的 LLMs 突現特性
2.2.1 LLMs 的零樣本與少樣本學習能力
2.2.2 突現現象：是錯覺還是新能力？
2.3 大量訓練資料背後的難題
2.3.1 把偏見編碼進模型中
2.3.2 敏感資料
2.4 總結
```
```
第 3 章 LLMs 的隱私風險與法規應對
3.1 改善 LLMs 生成結果安全性的方法
3.1.1 後處理偵測
3.1.2 內容過濾、條件式預訓練
3.1.3 基於人類回饋的強化式學習（RLHF）
3.1.4 基於 AI 回饋的強化式學習（RLAIF）
3.2 使用者隱私與商用風險
3.2.1 無意間造成的資訊洩漏
3.2.2 與聊天機器人互動的建議
3.3 資料保護的政策與法規
3.3.1 國際標準與資料保護法
3.3.2 聊天機器人符合 GDPR 嗎？
3.3.3 美國校園中的隱私權管制
3.3.4 企業政策
3.4 總結
```
```
第 4 章 合成媒體創作與著作權爭議
4.1 深偽技術與合成媒體的崛起
4.1.1 創造合成媒體的常用技術
4.1.2 合成媒體的功與過
4.1.3 合成媒體的偵測技術與應對策略
4.2 以生成式 AI 翻轉創作過程
4.2.1 行銷上的應用
4.2.2 藝術創作
4.3 LLM 時代的著作權與訴訟案件
4.3.1 合理使用的概念與四大要素
4.3.2 LLM 企業面臨的法律訴訟
4.3.3 網路資料的使用與授權
4.4 總結
```
```
第5 章 LLMs 的濫用與對抗式攻擊
5.1 資訊安全與社交工程
5.1.1 生成式 AI 的雙面性
5.1.2 魚叉式釣魚攻擊的進化
5.1.3 ChatGPT 對釣魚與惡意程式的影響
5.1.4 程式碼即服務的資安威脅
5.1.5 資料下毒：模型訓練的隱藏威脅
5.1.6 提示詞注入與越獄攻擊
5.1.7 面對生成式 AI 威脅的解決之道
5.2 資訊失序：對抗性敘事
5.2.1 認知作戰的範疇與定義
5.2.2 生成式AI 的潛在濫用
5.2.3 深偽技術與政治戰
5.2.4 對抗性敘事的監管挑戰
5.2.5 建立全球性對策機構
5.3 政治偏見與競選活動
5.3.1 聊天機器人的政治立場
5.3.2 偏見的來源與中立挑戰
5.3.3 LLMs 對選舉的潛在影響
5.3.4 馬斯克對 AI 的批評與探索
5.4 AI 幻覺的成因與改善方法
5.4.1 LLMs 的運作方法所導致
5.4.2 知識圖譜與 LLMs 內隱知識
5.4.3 改善幻覺的策略
5.5 專業領域中的濫用
5.5.1 律師濫用的案例
5.5.2 賺錢建議的魅力與濫用隱憂
5.5.3 醫療領域的成就與局限
5.5.4 投資顧問的挑戰與監管問題
5.5.5 生成式 AI 的倫理與責任
5.5.6 使用者與開發者的共同責任
5.6 總結
```
```
第 6 章 善用 AI 工具提高生產力
6.1 在醫療、法律、金融等專業領域中運用
6.1.1 協助醫師處理行政作業、提高與病人互動品質
6.1.2 在法律案件研究、證據開示和文書上的應用
6.1.3 為金融投資與銀行客服加持
6.1.4 與 LLMs 共同創作
6.2 AI 程式設計輔助工具
6.2.1 自動撰寫程式碼說明
6.2.2 自動撰寫正規表達式
6.2.3 AI 程式助手 vs. 程式討論平台
6.3 工作與生活中的應用
6.3.1 學習方式的改變
6.3.2 重新定義購物體驗
6.3.3 AI 代理能與環境互動並靈活調整
6.3.4 代理化 LLMs：拓展 AI 的應用潛力
6.3.5 善用聊天機器人設計個人化計畫
6.3.6 從行政工作到未來內容生態的變革
6.4 生成式 AI 在教育中的足跡
6.4.1 教育工作者對 ChatGPT 的正反面態度
6.4.2 引入 AI 科技對學習的好處
6.5 偵測 AI 生成文本
6.5.1 離群值偵測技術
6.5.2 用 DetectGPT 檢測機率曲率
6.5.3 分類器偵測技術
6.5.4 文字浮水印技術
6.6 LLM 對工作和經濟的影響
6.6.1 正面的觀點
6.6.2 負面的觀點
6.6.3 生成式 AI 對就業的影響
6.7 總結
```
```
第 7 章 與聊天機器人建立人機連結
7.1 以社交互動為目的的聊天機器人
7.1.1 從情感陪伴到倫理爭議
7.1.2 人機情感連結的商業化應用
7.2 向聊天機器人尋求陪伴的原因
7.2.1 孤獨流行病
7.2.2 情感依附理論與聊天機器人
7.3 人機關係的好與壞
7.3.1 基於規則 AI 聊天機器人的優勢
7.3.2 從社會滲透論看人機關係
7.3.3 人機關係的商業化與社會影響
7.3.4 性別觀念影響對話式 AI 技術開發
7.4 探索與聊天機器人良性互動之道
7.4.1 避免一味追求互動的榨取式科技、欺騙性設計
7.4.2 朝負責任科技方向轉型
7.4.3 Character.AI 平台的用戶行為
7.4.4 開發商的道德責任與技術手段
7.5 總結
```
```
第 8 章 生成式 AI 的未來發展與監管方向
8.1 自然語言成為與電腦溝通的介面
8.2 AI Agents（代理）將解鎖更多可能性
8.3 客製化個人助理
8.4 從倫理角度看 AI 監管
8.4.1 北美的監管狀況
8.4.2 歐盟的監管狀況
8.4.3 中國的監管狀況
8.4.4 企業自律
8.5 邁向全球 AI 治理架構
8.6 總結
```
```
第 9 章 拓展視野：AGI、AI 意識、環境影響、開源 LLM
9.1 通ghjgghw2用人工智慧 AGI
9.1.1 AGI 是什麼？
9.1.2 山姆．阿特曼對 AGI 的願景
9.1.3 優生學、超人類主義、後人類
9.1.4 長期主義對 AGI 的憂慮
9.2 AI 的感知與意識
9.2.1 感知與意識是什麼？
9.2.2 意識從哪裡產生？
9.2.3 意識思考與後設認知
9.2.4 AI 意識的研究持續進行
9.3 LLM 對環境的影響
9.3.1 從硬體生產到運算需求的全面影響
9.3.2 生成式 AI 的環境成本與碳足跡報告
9.4 改變 LLM 生態的開源社群
9.4.1 LlaMA 洩漏權重，促進開源 LLM 快速發展
9.4.2 DeepSeek-R1 權重開源，打破美國技術壟斷
9.4.3 開源與封閉 LLM 的優缺點
9.4.4 如何為開源社群盡一份心力
9.5 總結
```
